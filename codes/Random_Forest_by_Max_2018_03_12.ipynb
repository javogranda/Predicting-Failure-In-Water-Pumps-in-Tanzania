{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Analytical Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library with the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load numpy\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Done by Dataiku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data for independent variables\n",
    "train_set = pd.read_csv('C:/Users/yangj/Documents/GitHub/pumpitup_1/data/data_to_go_max/train_set_to_go.csv')\n",
    "test_set = pd.read_csv('C:/Users/yangj/Documents/GitHub/pumpitup_1/data/data_to_go_max/test_set_to_go.csv')\n",
    "\n",
    "#loading target_set\n",
    "target_train = pd.read_csv('C:/Users/yangj/Documents/GitHub/pumpitup_1/data/target_vars.csv')\n",
    "\n",
    "#submission format\n",
    "sub_form = pd.read_csv('C:/Users/yangj/Documents/GitHub/pumpitup_1/data/SubmissionFormat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorize Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['functional', 'non functional', 'functional needs repair'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.factorize(target_train['status_group'])[0]\n",
    "y_index =pd.factorize(target_train['status_group'])[1]\n",
    "y_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'amount_tsh', 'since_date_recorded_days', 'funder', 'installer',\n",
       "       'wpt_name', 'basin', 'subvillage', 'region', 'region_code',\n",
       "       'district_code', 'lga', 'population', 'public_meeting', 'scheme_name',\n",
       "       'permit', 'construction_year', 'extraction_type_class', 'management',\n",
       "       'user_group', 'payment', 'water_soft', 'quantity', 'source_type',\n",
       "       'source_class', 'waterpoint_type_group', 'gps_height', 'longitude',\n",
       "       'latitude', 'train_set'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Train_set and Test_set into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.drop(labels = ['id','train_set'], axis = 1)\n",
    "x_train[['funder', 'installer', 'basin','region_code', 'district_code', 'public_meeting','construction_year',\\\n",
    "        'extraction_type_class', 'management', 'payment', 'source_type', 'waterpoint_type_group',\\\n",
    "        'region','water_soft','permit','scheme_name','source_class','lga','user_group','wpt_name','subvillage']]\\\n",
    "= x_train[['funder', 'installer', 'basin','region_code', 'district_code', 'public_meeting','construction_year',\\\n",
    "        'extraction_type_class', 'management', 'payment', 'source_type', 'waterpoint_type_group',\\\n",
    "        'region','water_soft','permit','scheme_name','source_class','lga','user_group','wpt_name','subvillage']]\\\n",
    "        .apply(lambda x: pd.factorize(x)[0])\n",
    "x_train = x_train.fillna(0)\n",
    "\n",
    "x_test = test_set.drop(labels = ['id','train_set'], axis = 1)\n",
    "x_test[['funder', 'installer', 'basin','region_code', 'district_code', 'public_meeting','construction_year',\\\n",
    "        'extraction_type_class', 'management', 'payment', 'source_type', 'waterpoint_type_group',\\\n",
    "        'region','water_soft','permit','scheme_name','source_class','lga','user_group','wpt_name','subvillage']]\\\n",
    "= x_test[['funder', 'installer', 'basin','region_code', 'district_code', 'public_meeting','construction_year',\\\n",
    "        'extraction_type_class', 'management', 'payment', 'source_type', 'waterpoint_type_group',\\\n",
    "        'region','water_soft','permit','scheme_name','source_class','lga','user_group','wpt_name','subvillage']]\\\n",
    "        .apply(lambda x: pd.factorize(x)[0])\n",
    "x_test = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Random Sample(90%) to train the data, and left 10% to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = shuffle(x_train,random_state = 0)\n",
    "y = shuffle(y, random_state = 0)\n",
    "x_train_test = x_train[:5940]\n",
    "x_train = x_train[5940:]\n",
    "y_test = y[:5940]\n",
    "y = y[5940:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimators: @Falcon is wrong, in general the more trees the less likely the algorithm is to overfit. So try increasing this. The lower this number, the closer the model is to a decision tree, with a restricted feature set.\n",
    "\n",
    "### max_features: try reducing this number (try 30-50% of the number of features). This determines how many features each tree is randomly assigned. The smaller, the less likely to overfit, but too small will start to introduce under fitting.\n",
    "\n",
    "\n",
    "### max_depth: Experiment with this. This will reduce the complexity of the learned models, lowering over fitting risk. Try starting small, say 5-10, and increasing you get the best result.\n",
    "\n",
    "\n",
    "### min_samples_leaf: Try setting this to values greater than one. This has a similar effect to the max_depth parameter, it means the branch will stop splitting once the leaves have that number of samples each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = pd.DataFrame(columns=['i','precision'])\n",
    "for i in range(20,30):\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "    clf = RandomForestClassifier(n_jobs=2, n_estimators = 50, random_state=0, criterion='entropy', max_features = 0.4, max_depth = i)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "    clf.fit(x_train, y)\n",
    "\n",
    "    feature_importances = pd.DataFrame(list(zip(x_train, clf.feature_importances_)))\n",
    "    feature_importances.columns = ['feature','importance']\n",
    "    feature_importances = feature_importances.sort_values(by = 'importance', axis = 0, ascending = 0)\n",
    "    feature_importances\n",
    "\n",
    "    y_pred = clf.predict(x_train_test)\n",
    "    a = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    precision = np.diag(a).sum()/a.sum().sum()\n",
    "    precisions = precisions.append({'i': i, 'precision': precision}, ignore_index = True)\n",
    "precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth = 10, find best min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.757407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.757407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.757407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.757407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.758923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.758923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.758923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.758923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.757407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.757407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      i  precision\n",
       "0  0.50   0.757407\n",
       "1  0.51   0.757407\n",
       "2  0.52   0.757407\n",
       "3  0.53   0.757407\n",
       "4  0.54   0.758923\n",
       "5  0.55   0.758923\n",
       "6  0.56   0.758923\n",
       "7  0.57   0.758923\n",
       "8  0.58   0.757407\n",
       "9  0.59   0.757407"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions = pd.DataFrame(columns=['i','precision'])\n",
    "for i in np.arange(0.5,0.6,0.01):\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "    clf = RandomForestClassifier(n_jobs=2, n_estimators = 50, random_state=0, criterion='entropy',\\\n",
    "                                 max_features = i, max_depth = 10)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "    clf.fit(x_train, y)\n",
    "\n",
    "    feature_importances = pd.DataFrame(list(zip(x_train, clf.feature_importances_)))\n",
    "    feature_importances.columns = ['feature','importance']\n",
    "    feature_importances = feature_importances.sort_values(by = 'importance', axis = 0, ascending = 0)\n",
    "    feature_importances\n",
    "\n",
    "    y_pred = clf.predict(x_train_test)\n",
    "    a = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    precision = np.diag(a).sum()/a.sum().sum()\n",
    "    precisions = precisions.append({'i': i, 'precision': precision}, ignore_index = True)\n",
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## max_depth = 10, min_samples_leaf = 0.55， find best min_sample_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.750505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.742088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.737205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151.0</td>\n",
       "      <td>0.737710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>181.0</td>\n",
       "      <td>0.738721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>211.0</td>\n",
       "      <td>0.736364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>241.0</td>\n",
       "      <td>0.735185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>271.0</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i  precision\n",
       "0    1.0   0.758923\n",
       "1   31.0   0.750505\n",
       "2   61.0   0.747475\n",
       "3   91.0   0.742088\n",
       "4  121.0   0.737205\n",
       "5  151.0   0.737710\n",
       "6  181.0   0.738721\n",
       "7  211.0   0.736364\n",
       "8  241.0   0.735185\n",
       "9  271.0   0.734848"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions = pd.DataFrame(columns=['i','precision'])\n",
    "for i in np.arange(1,300,30):\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "    clf = RandomForestClassifier(n_jobs=2, n_estimators = 50, random_state=0, criterion='entropy',\\\n",
    "                                 max_features = 0.55, max_depth = 10, min_samples_leaf = 1)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "    clf.fit(x_train, y)\n",
    "\n",
    "    feature_importances = pd.DataFrame(list(zip(x_train, clf.feature_importances_)))\n",
    "    feature_importances.columns = ['feature','importance']\n",
    "    feature_importances = feature_importances.sort_values(by = 'importance', axis = 0, ascending = 0)\n",
    "    feature_importances\n",
    "\n",
    "    y_pred = clf.predict(x_train_test)\n",
    "    a = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    precision = np.diag(a).sum()/a.sum().sum()\n",
    "    precisions = precisions.append({'i': i, 'precision': precision}, ignore_index = True)\n",
    "precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth = 10, min_samples_leaf = 0.55， find best min_sample_leaf = 1, try large n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627946127946128"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions = pd.DataFrame(columns=['i','precision'])\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_jobs=2, n_estimators = 2000, random_state=0, criterion='gini',\\\n",
    "                                 max_features = 0.55, max_depth = 10, min_samples_leaf = 1)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(x_train, y)\n",
    "\n",
    "feature_importances = pd.DataFrame(list(zip(x_train, clf.feature_importances_)))\n",
    "feature_importances.columns = ['feature','importance']\n",
    "feature_importances = feature_importances.sort_values(by = 'importance', axis = 0, ascending = 0)\n",
    "feature_importances\n",
    "\n",
    "y_pred = clf.predict(x_train_test)\n",
    "a = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "precision = np.diag(a).sum()/a.sum().sum()\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Using Classifier Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.diag(a).sum()/a.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['predict'] = clf.predict(x_test)\n",
    "test_set['predict'] = test_set['predict'].replace(to_replace = [0,1,2], value = y_index)\n",
    "to_sub = test_set[['id','predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(sub_form, to_sub, on = 'id')\n",
    "submission = submission.drop('status_group', axis = 1)\n",
    "submission.columns = ['id', 'status_group']\n",
    "submission.to_csv('submission.csv',header = True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
